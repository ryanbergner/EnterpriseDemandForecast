# ğŸš€ Enterprise Time Series Forecasting System

A production-ready, enterprise-grade forecasting pipeline for demand prediction using statistical models, machine learning, and deep learning. Built on Apache Spark with comprehensive MLflow integration and advanced feature engineering.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PySpark](https://img.shields.io/badge/PySpark-3.5.4+-orange.svg)](https://spark.apache.org/)
[![MLflow](https://img.shields.io/badge/MLflow-2.15.1+-green.svg)](https://mlflow.org/)

---

## ğŸ¯ Overview

This system provides a complete end-to-end pipeline for time series demand forecasting with enterprise features:

- **ğŸ“Š Multi-Model Support**: Spark ML (RF, GBT, LR), StatsForecast (ARIMA, ETS, Croston), TabPFN, Neural Networks
- **ğŸ”§ Advanced Feature Engineering**: 80+ automated features including trend, EWMA, interactions
- **âœ… Data Quality Validation**: Automated quality checks and smart imputation
- **ğŸ“ Intelligent Training**: Early stopping, cross-validation, feature importance analysis
- **ğŸ”® Uncertainty Quantification**: Confidence intervals and prediction uncertainty metrics
- **ğŸ“ˆ Ensemble Methods**: Simple/weighted averaging, median, stacking
- **ğŸ“± Interactive Dashboards**: Plotly-based visualization and model comparison
- **âš™ï¸ Unified CLI**: Single interface for all operations
- **â˜ï¸ Cloud-Ready**: Native Azure Databricks and MLflow integration

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ cli.py                          # Unified command-line interface
â”œâ”€â”€ config.py                       # Central configuration
â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚
â”œâ”€â”€ main_train_m5.py                # Training script for M5 dataset (local)
â”œâ”€â”€ main_train_databricks.py        # Training script for Azure Databricks
â”œâ”€â”€ main_train.py                   # Generic training script
â”œâ”€â”€ main_inference.py               # Inference and prediction script
â”œâ”€â”€ upload_custom_data.py           # Custom data validation and upload
â”œâ”€â”€ EDA.py                          # Exploratory Data Analysis notebook
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ preprocess.py           # Data aggregation and preprocessing
â”‚   â”‚   â””â”€â”€ imputation.py           # Smart null handling (7 strategies)
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # Core feature engineering
â”‚   â”‚   â”œâ”€â”€ trend_features.py       # Trend, growth, momentum features
â”‚   â”‚   â”œâ”€â”€ ewma_features.py        # EWMA and adaptive smoothing
â”‚   â”‚   â””â”€â”€ interaction_features.py # Feature interactions and polynomials
â”‚   â”‚
â”‚   â”œâ”€â”€ model_training/
â”‚   â”‚   â”œâ”€â”€ ml_models.py            # Spark ML model training
â”‚   â”‚   â”œâ”€â”€ stats_models.py         # Statistical model training
â”‚   â”‚   â”œâ”€â”€ early_stopping.py       # Early stopping for tree models
â”‚   â”‚   â”œâ”€â”€ feature_importance.py   # Feature importance analysis
â”‚   â”‚   â””â”€â”€ ensemble.py             # Ensemble prediction methods
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ inference.py            # Model inference
â”‚   â”‚   â””â”€â”€ confidence_intervals.py # Prediction uncertainty
â”‚   â”‚
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ data_quality.py         # Data quality validators
â”‚   â”‚   â””â”€â”€ time_series_cv.py       # Time-series cross-validation
â”‚   â”‚
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ model_dashboard.py      # Interactive dashboards
â”‚
â””â”€â”€ data/                           # Data directory (not in git)
    â”œâ”€â”€ m5/                         # M5 dataset
    â””â”€â”€ custom/                     # Custom datasets
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd <repository-name>

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download M5 Dataset

The M5 dataset is the default dataset for this system. Download it from [Kaggle M5 Forecasting Competition](https://www.kaggle.com/c/m5-forecasting-accuracy/data):

```bash
# Create data directory
mkdir -p data/m5

# Download and place these files in data/m5/:
# - sales_train_validation.csv (required)
# - calendar.csv (optional)
# - sell_prices.csv (optional)
```

### 3. Train Your First Model

```bash
# Train models on M5 dataset (local)
python main_train_m5.py \
  --data-path data/m5/sales_train_validation.csv \
  --experiment-name M5_Experiment \
  --max-items 100

# View results in MLflow UI
mlflow ui
# Open browser to http://localhost:5000
```

### 4. Make Predictions

```python
from main_inference import main_inference
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Forecasting").getOrCreate()
df = spark.read.csv("data/m5/sales_train_validation.csv", header=True)

predictions = main_inference(
    df=df,
    date_column="OrderDate",
    product_id_column="item_id",
    quantity_column="Quantity",
    month_end_column="MonthEndDate",
    target_path="predictions/",
    ind_full_history=0  # 0 = next month only, 1 = full history
)
```

---

## ğŸ¨ Using the Unified CLI

The CLI provides a single interface for all operations:

### Validate Data Quality

```bash
python cli.py validate \
  --data data/m5/sales_train_validation.csv \
  --date-col MonthEndDate \
  --target-col Quantity \
  --report-path data_quality_report.json
```

### Train Models with All Features

```bash
python cli.py train \
  --data data/m5/sales_train_validation.csv \
  --models rf,gbt,lr,stats \
  --categories all \
  --cv-folds 5 \
  --early-stopping \
  --feature-selection \
  --experiment-name Production_Models
```

### Evaluate Models with Confidence Intervals

```bash
python cli.py evaluate \
  --model-path models:/MyModel/Production \
  --data test_data.csv \
  --metrics rmse,mae,mape,r2 \
  --confidence-intervals \
  --output evaluation_results.json
```

### Generate Predictions

```bash
python cli.py predict \
  --model-path models/best_model \
  --data input_data.csv \
  --horizon 12 \
  --ensemble \
  --ensemble-strategy weighted_average \
  --output predictions.csv
```

### Compare Models

```bash
python cli.py compare \
  --experiment "M5_Experiment" \
  --metric rmse \
  --top-k 5 \
  --output model_comparison.csv
```

### Generate Dashboard

```bash
python cli.py dashboard \
  --results results.json \
  --output dashboard.html \
  --theme plotly_white
```

---

## ğŸ“Š Using Custom Data

### Step 1: Prepare Your Dataset

Your CSV must have these columns:
- **date**: Date column (any standard format: YYYY-MM-DD, MM/DD/YYYY, etc.)
- **item_id**: Product/item identifier
- **quantity**: Demand/sales quantity (numeric)

Optional columns enhance the model:
- `store_id`, `cat_id`, `dept_id`, `state_id`

### Step 2: Upload and Validate

```bash
# Auto-detect column names
python upload_custom_data.py \
  --input-path my_sales_data.csv \
  --output-path data/custom/validated_data.csv

# Or specify column names explicitly
python upload_custom_data.py \
  --input-path my_sales_data.csv \
  --output-path data/custom/validated_data.csv \
  --date-col OrderDate \
  --item-id-col SKU \
  --quantity-col SalesQty \
  --format parquet
```

The script automatically:
- âœ… Validates schema and data types
- âœ… Checks data quality (missing values, outliers, date gaps)
- âœ… Maps column names to standard format
- âœ… Performs data quality checks
- âœ… Saves validated data ready for training

### Step 3: Train on Custom Data

```bash
python main_train.py \
  --data-path data/custom/validated_data.csv \
  --experiment-name Custom_Dataset \
  --max-items 500
```

---

## ğŸ¤– Available Models

### Statistical Models (StatsForecast)
- **Seasonal Exponential Smoothing (ETS)**: Handles trend and seasonality
- **Croston Classic**: Optimized for intermittent demand
- **AutoARIMA**: Automatic ARIMA model selection (optional)
- **Holt-Winters**: Triple exponential smoothing (optional)

### Machine Learning Models (Spark ML)
- **Linear Regression**: Fast baseline model
- **Random Forest**: Ensemble tree-based model with hyperparameter tuning
- **Gradient Boosted Trees (GBT)**: Advanced gradient boosting with early stopping
- **TabPFN**: Foundation model for tabular data (optional, if installed)

### Neural Networks (Optional)
- **TensorFlow/Keras**: Deep learning models for complex patterns
- **LSTM**: Long Short-Term Memory for sequential data

---

## ğŸ”§ Advanced Features

### 1. Feature Engineering (80+ Features)

The system automatically creates comprehensive features:

**Basic Features** (`feature_engineering.py`):
- Moving averages (4, 8, 12 months)
- Lag features (1-12 months)
- Statistical features (CV, avg demand interval)
- Time features (month, year, day of week)
- Product categorization (Smooth, Erratic, Intermittent, Lumpy)

**Trend Features** (`trend_features.py`):
- Growth rates (3, 6, 12 months)
- Momentum and acceleration
- Trend strength and direction
- Lifecycle stage classification
- Change point detection

**EWMA Features** (`ewma_features.py`):
- Exponentially weighted moving averages
- EWMA momentum (MACD-style)
- Volatility measures
- Adaptive EWMA with dynamic alpha

**Interaction Features** (`interaction_features.py`):
- Multiplicative interactions (lag Ã— seasonality)
- Polynomial features (degree 2)
- Ratio features (value/MA, lag_1/lag_12)
- Category-specific features

```python
from src.feature_engineering.trend_features import add_trend_features
from src.feature_engineering.ewma_features import add_ewma_features
from src.feature_engineering.interaction_features import add_all_interaction_features

# Add all advanced features
df = add_trend_features(df, 'Quantity', 'MonthEndDate', 'item_id')
df = add_ewma_features(df, 'Quantity', 'MonthEndDate', 'item_id')
df = add_all_interaction_features(df, 'Quantity', 'MonthEndDate', 'item_id')
```

### 2. Data Quality Validation

```python
from src.validation.data_quality import DataQualityValidator

validator = DataQualityValidator()
report = validator.validate(
    df,
    date_col="MonthEndDate",
    product_col="item_id",
    target_col="Quantity"
)
validator.print_report(report)

# Checks performed:
# - Missing data patterns
# - Outlier detection (Z-score, IQR)
# - Time gap detection
# - Seasonality strength
# - Zero-value patterns
# - Distribution analysis
```

### 3. Smart Imputation

```python
from src.preprocessing.imputation import TimeSeriesImputer, impute_with_auto_strategy

# Auto-select best strategy
df_imputed = impute_with_auto_strategy(
    df,
    value_col='Quantity',
    date_col='MonthEndDate',
    product_col='item_id'
)

# Or choose specific strategy
imputer = TimeSeriesImputer(strategy='forward_fill_decay', decay_rate=0.95)
df_imputed = imputer.fit_transform(df, 'Quantity', 'MonthEndDate', 'item_id')
```

**Available Strategies**:
- `forward_fill`: Simple forward fill
- `forward_fill_decay`: Forward fill with exponential decay
- `backward_fill`: Backward fill
- `seasonal`: Use same period from previous year
- `mean`: Mean imputation
- `median`: Median imputation
- `interpolate`: Linear interpolation

### 4. Time-Series Cross-Validation

```python
from src.validation.time_series_cv import TimeSeriesCV

# Expanding window (train size grows)
cv = TimeSeriesCV(n_splits=5, strategy='expanding')
for fold_num, (train_df, test_df) in enumerate(cv.split(df, 'MonthEndDate')):
    print(f"Fold {fold_num+1}")
    model = train_model(train_df)
    metrics = evaluate_model(model, test_df)
    print(f"  RMSE: {metrics['rmse']:.2f}")

# Sliding window (fixed train size)
cv_sliding = TimeSeriesCV(n_splits=5, strategy='sliding', train_size=0.6)
```

### 5. Early Stopping

```python
from src.model_training.early_stopping import EarlyStopping
from pyspark.ml.regression import GBTRegressor

early_stop = EarlyStopping(patience=5, min_delta=0.001)
model = early_stop.train_with_early_stopping(
    model=GBTRegressor(),
    train_df=train_df,
    feature_cols=['Quantity', 'ma_4_month', 'lag_1', 'month'],
    label_col='lead_month_1',
    validation_split=0.2
)

print(f"Best iteration: {early_stop.best_iteration}")
print(f"Best metric: {early_stop.best_metric:.4f}")
```

### 6. Feature Importance Analysis

```python
from src.model_training.feature_importance import (
    FeatureImportanceAnalyzer,
    automatic_feature_selection
)

# Get feature importance
analyzer = FeatureImportanceAnalyzer(top_k=20)
importance_dict = analyzer.get_feature_importance(model, feature_names)
analyzer.print_feature_importance(importance_dict)

# Automatic feature selection
selected_features, report = automatic_feature_selection(
    model, train_df, test_df,
    feature_cols, label_col='lead_month_1',
    importance_threshold=0.01,
    max_features=50
)
```

### 7. Ensemble Methods

```python
from src.model_training.ensemble import (
    EnsemblePredictor,
    learn_ensemble_weights,
    StackingEnsemble
)

# Learn optimal weights from validation data
models = {'RF': rf_model, 'GBT': gbt_model, 'LR': lr_model}
weights = learn_ensemble_weights(models, val_df, 'lead_month_1')

# Weighted average ensemble
ensemble = EnsemblePredictor(strategy='weighted_average', weights=weights)
predictions_df = ensemble.predict(models, test_df)

# Stacking ensemble (meta-learner)
from pyspark.ml.regression import LinearRegression
stacker = StackingEnsemble(meta_learner=LinearRegression())
stacker.fit(models, train_df, val_df, 'lead_month_1')
predictions_df = stacker.predict(test_df)
```

**Ensemble Strategies**:
- `simple_average`: Equal weights
- `weighted_average`: Learned weights based on validation performance
- `median`: Robust to outliers
- `stacking`: Meta-learner trained on base predictions

### 8. Prediction Confidence Intervals

```python
from src.inference.confidence_intervals import (
    PredictionIntervals,
    UncertaintyQuantifier
)

# Add confidence intervals
pi = PredictionIntervals(confidence_level=0.95)
predictions_with_intervals = pi.add_intervals(
    model, test_df, feature_cols,
    label_col='lead_month_1',
    method='residual'  # or 'quantile', 'bootstrap'
)

# Comprehensive uncertainty quantification
uq = UncertaintyQuantifier(confidence_level=0.95)
predictions_with_uncertainty = uq.quantify_uncertainty(
    model, test_df, feature_cols, 'lead_month_1'
)

predictions_with_uncertainty.select(
    'item_id', 'prediction',
    'lower_bound', 'upper_bound',
    'interval_width', 'confidence_score'
).show()
```

### 9. Interactive Dashboards

```python
from src.visualization.model_dashboard import (
    ModelDashboard,
    create_comprehensive_dashboard
)

# Create comparison dashboard
dashboard = ModelDashboard(theme='plotly_white')
dashboard.create_comparison_dashboard(
    results={
        'RF': {'rmse': 10.5, 'mae': 8.2, 'r2': 0.85},
        'GBT': {'rmse': 9.8, 'mae': 7.8, 'r2': 0.87},
        'Ensemble': {'rmse': 9.2, 'mae': 7.1, 'r2': 0.89}
    },
    output_path='model_comparison.html',
    title='Model Performance Dashboard'
)

# Comprehensive dashboard suite
files = create_comprehensive_dashboard(
    model_results=results_dict,
    feature_importance=importance_dict,
    output_dir='./dashboards',
    base_filename='analysis'
)
```

---

## â˜ï¸ Azure Databricks Deployment

### Option 1: Using Configuration File

```bash
# Create config from template
cp azure_config.py.template azure_config.py

# Edit azure_config.py with your credentials
# AZURE_STORAGE_ACCOUNT_NAME = "myaccount"
# AZURE_STORAGE_ACCOUNT_KEY = "mykey"
# AZURE_STORAGE_CONTAINER_NAME = "m5-forecasting"
```

### Option 2: Using Environment Variables

```bash
export AZURE_STORAGE_ACCOUNT_NAME="myaccount"
export AZURE_STORAGE_ACCOUNT_KEY="mykey"
export AZURE_STORAGE_CONTAINER_NAME="m5-forecasting"
```

### Option 3: Using Databricks Secrets

```python
# In Databricks notebook
account_name = dbutils.secrets.get(scope="azure-storage", key="account-name")
account_key = dbutils.secrets.get(scope="azure-storage", key="account-key")
```

### Upload Data to Azure Blob Storage

```bash
# Using Azure CLI
az storage blob upload-batch \
  --account-name myaccount \
  --destination m5-forecasting \
  --source data/m5/ \
  --pattern "*.csv"
```

### Run Training on Databricks

```bash
# As a notebook
%run /Workspace/path/to/main_train_databricks

# As a job
python main_train_databricks.py \
  --experiment-name M5_Production \
  --max-items 500 \
  --user-email your.email@company.com
```

---

## ğŸ“ˆ Model Evaluation Metrics

All models are evaluated using:

- **RMSE** (Root Mean Squared Error): Penalizes large errors
- **MAE** (Mean Absolute Error): Average absolute difference
- **MAPE** (Mean Absolute Percentage Error): Relative error percentage
- **RÂ²** (Coefficient of Determination): Explained variance

Results are automatically logged to MLflow:

```bash
# View in MLflow UI
mlflow ui --port 5000

# Or access programmatically
import mlflow
runs = mlflow.search_runs(experiment_names=["M5_Experiment"])
best_run = runs.sort_values('metrics.rmse').iloc[0]
print(f"Best RMSE: {best_run['metrics.rmse']:.2f}")
```

---

## ğŸ“ Configuration

Edit `config.py` to customize:

```python
# Feature engineering
MA_WINDOWS = [4, 8, 12]  # Moving average windows
LAG_FEATURES = [1, 2, 3, 4, 5, 6, 11, 12]  # Lag features

# Training
TRAIN_SPLIT_RATIO = 0.8  # 80% train, 20% test
MAX_DISTINCT_ITEMS = 100  # Limit items for testing
MIN_ORDERS = 5  # Minimum orders required per item

# Spark ML hyperparameters
SPARK_ML_PARAMS = {
    "RandomForest": {
        "maxDepth": [2, 3, 5, 7],
        "numTrees": [50, 100, 200]
    },
    "GradientBoostedTrees": {
        "maxDepth": [3, 5, 7],
        "maxIter": [10, 20, 50]
    }
}
```

---

## ğŸ“Š Expected Performance Improvements

With all advanced features enabled:

| Feature | RMSE Reduction | Dev Time |
|---------|---------------|----------|
| Trend Features | 5-10% | 2 hours |
| EWMA Features | 3-7% | 2 hours |
| Feature Interactions | 7-12% | 3 hours |
| Ensemble Methods | 10-20% | 5 hours |
| Data Quality + Imputation | 5-10% | 7 hours |
| **Total Expected** | **20-40%** | **36 hours** |

---

## ğŸ› Troubleshooting

### Issue: "Cannot find M5 dataset"
**Solution**: Download from Kaggle and place `sales_train_validation.csv` in `data/m5/`

### Issue: "Azure Blob Storage access denied"
**Solution**: Verify credentials in `azure_config.py` or environment variables

### Issue: "OutOfMemoryError in Spark"
**Solution**: 
```python
# Increase Spark memory
spark = SparkSession.builder \
    .config("spark.driver.memory", "8g") \
    .config("spark.executor.memory", "8g") \
    .getOrCreate()

# Or reduce max items
python main_train_m5.py --max-items 50
```

### Issue: "TabPFN not available"
**Solution**: TabPFN is optional. Install with:
```bash
pip install tabpfn
```

### Issue: "Feature columns not found"
**Solution**: Ensure feature engineering completed successfully. Check for null values:
```python
df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()
```

---

## ğŸ“š Documentation

- **[IMPROVEMENTS.md](IMPROVEMENTS.md)**: Detailed documentation of all 12 major improvements
- **[NEW_FEATURES_SUMMARY.md](NEW_FEATURES_SUMMARY.md)**: Quick reference for new features
- **[SETUP_GUIDE.md](SETUP_GUIDE.md)**: Detailed setup instructions
- **Docstrings**: Every function has comprehensive docstrings with examples

### CLI Help

```bash
# General help
python cli.py --help

# Command-specific help
python cli.py train --help
python cli.py evaluate --help
python cli.py predict --help
```

---

## ğŸ”— External Resources

- [M5 Competition](https://www.kaggle.com/c/m5-forecasting-accuracy)
- [StatsForecast Documentation](https://nixtla.github.io/statsforecast/)
- [PySpark ML Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Azure Databricks Documentation](https://docs.microsoft.com/en-us/azure/databricks/)

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

[Add your license information here]

---

## ğŸ’¡ Key Features Summary

âœ… **80+ Automated Features**: Trend, EWMA, interactions, and more  
âœ… **Multi-Model Support**: Statistical + ML + Deep Learning  
âœ… **Data Quality Validation**: Automated checks before training  
âœ… **Smart Imputation**: 7 strategies with auto-selection  
âœ… **Early Stopping**: Prevents overfitting, faster training  
âœ… **Feature Importance**: Understand what drives predictions  
âœ… **Ensemble Methods**: 10-20% additional improvement  
âœ… **Confidence Intervals**: Quantify prediction uncertainty  
âœ… **Interactive Dashboards**: Beautiful Plotly visualizations  
âœ… **Unified CLI**: Single interface for all operations  
âœ… **Cloud-Ready**: Native Azure Databricks support  
âœ… **Production-Ready**: Comprehensive logging and error handling

---

## ğŸ¯ Quick Links

- **Train first model**: `python main_train_m5.py --data-path data/m5/sales_train_validation.csv`
- **Validate your data**: `python cli.py validate --data your_data.csv`
- **Upload custom data**: `python upload_custom_data.py --input-path your_data.csv --output-path data/custom/`
- **View MLflow UI**: `mlflow ui` then open http://localhost:5000
- **Get help**: `python cli.py --help`

---

**Ready to forecast! ğŸš€ğŸ“ˆ**
